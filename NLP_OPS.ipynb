{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8268e07",
   "metadata": {},
   "source": [
    "# NLP Operations: Job Title Matching\n",
    "This notebook demonstrates various NLP techniques to vectorize job titles and a search term, and then ranks candidates by similarity. Techniques covered:\n",
    "- TF-IDF\n",
    "- Word2Vec (Google)\n",
    "- GloVe\n",
    "- FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52638f5",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports\n",
    "Install and import required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "840e55cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Osama\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Osama\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Osama\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Install required packages (uncomment if running for the first time)\n",
    "# !pip install pandas scikit-learn gensim nltk\n",
    "# !pip install glove-python-binary\n",
    "# !pip install fasttext\n",
    "# !pip install nltk pycocoevalcap\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import gensim.downloader as api\n",
    "from gensim.models import KeyedVectors\n",
    "import fasttext\n",
    "import fasttext.util\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "import random\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Import custom utility functions\n",
    "from utils import bleu_score\n",
    "\n",
    "# For CIDEr, we'll implement a simplified version\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"omw-1.4\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d735f83d",
   "metadata": {},
   "source": [
    "## 2. Load Data\n",
    "Load job titles from the Excel file and define a search term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb0b36a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selected search term: Student\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(\"potential-talents.xlsx\")\n",
    "possible_columns = [\n",
    "    \"job_title\",\n",
    "    \"title\",\n",
    "    \"position\",\n",
    "    \"role\",\n",
    "    \"job\",\n",
    "    \"designation\",\n",
    "    \"job title\",\n",
    "]\n",
    "job_title_column = None\n",
    "for col in df.columns:\n",
    "    if any(keyword in col.lower() for keyword in possible_columns):\n",
    "        job_title_column = col\n",
    "        break\n",
    "if not job_title_column:\n",
    "    raise ValueError(\"Job title column not found. Please specify it manually.\")\n",
    "job_titles = df[job_title_column].dropna().astype(str).tolist()\n",
    "\n",
    "# Filter job titles to only those with 1 or 2 words\n",
    "filtered_job_titles = [title for title in job_titles if 1 <= len(title.split()) <= 2]\n",
    "\n",
    "# Randomly select a search term from filtered job titles\n",
    "if filtered_job_titles:\n",
    "    search_term = random.choice(filtered_job_titles)\n",
    "else:\n",
    "    raise ValueError(\"No job titles with 1 or 2 words found.\")\n",
    "\n",
    "print(f\"Randomly selected search term: {search_term}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee2b628",
   "metadata": {},
   "source": [
    "## 3. TF-IDF Vectorization & Cosine Similarity\n",
    "Vectorize job titles and search term using TF-IDF, then rank candidates by similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "78bd229b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 job titles by TF-IDF similarity to search term:\n",
      "Student (Score: 1.000)\n",
      "Student at Chapman University (Score: 0.455)\n",
      "Student at Chapman University (Score: 0.455)\n",
      "Student at Chapman University (Score: 0.455)\n",
      "Student at Chapman University (Score: 0.455)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (Score: 0.371)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (Score: 0.371)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (Score: 0.371)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (Score: 0.371)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (Score: 0.371)\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer()\n",
    "corpus = job_titles + [search_term]\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "search_vec = X[-1]\n",
    "job_vecs = X[:-1]\n",
    "similarities = cosine_similarity(search_vec, job_vecs).flatten()\n",
    "ranked_indices = np.argsort(similarities)[::-1]\n",
    "print(\"Top 10 job titles by TF-IDF similarity to search term:\")\n",
    "for idx in ranked_indices[:10]:\n",
    "    print(f\"{job_titles[idx]} (Score: {similarities[idx]:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9af1a7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- LLM-based Candidate Ranking using Groq API (Llama 3 70B Versatile) ---\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "def rank_candidates_with_llm(\n",
    "    job_titles, search_term, model=\"llama3-70b-8192\"\n",
    "):  # Llama 3 70B Versatile\n",
    "    \"\"\"\n",
    "    Use Groq LLM API to rank job titles by relevance to the search term.\n",
    "    Args:\n",
    "        job_titles (list): List of job title strings.\n",
    "        search_term (str): The search term/job title to match against.\n",
    "        model (str): Groq model name (default: llama3-70b-8192).\n",
    "    Returns:\n",
    "        list: Ranked job titles (most relevant first).\n",
    "    \"\"\"\n",
    "    api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise ValueError(\n",
    "            \"GROQ_API_KEY not found in environment variables. Please set it in your .env file.\"\n",
    "        )\n",
    "    prompt = f\"\"\"\n",
    "You are an expert recruiter. Given the following list of candidate job titles, rank them from most to least relevant for the search term: '{search_term}'.\\n\\nJob Titles:\\n\"\"\"\n",
    "    for i, title in enumerate(job_titles, 1):\n",
    "        prompt += f\"{i}. {title}\\n\"\n",
    "    prompt += \"\\nReturn the ranking as a numbered list, most relevant first. Only include the job titles.\"\n",
    "\n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"temperature\": 0.2,\n",
    "    }\n",
    "    response = requests.post(\n",
    "        \"https://api.groq.com/openai/v1/chat/completions\",\n",
    "        headers=headers,\n",
    "        data=json.dumps(data),\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    result = response.json()\n",
    "    llm_output = result[\"choices\"][0][\"message\"][\"content\"]\n",
    "    # Parse the LLM output into a ranked list\n",
    "    ranked = [\n",
    "        line.split(\". \", 1)[-1].strip()\n",
    "        for line in llm_output.split(\"\\n\")\n",
    "        if line.strip() and line[0].isdigit()\n",
    "    ]\n",
    "    return ranked\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# ranked_list = rank_candidates_with_llm(job_titles, search_term)\n",
    "# print(\"LLM-ranked job titles:\")\n",
    "# for title in ranked_list:\n",
    "#     print(title)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff0288f",
   "metadata": {},
   "source": [
    "## 4. Word2Vec (Google News) Vectorization & Cosine Similarity\n",
    "Vectorize using pre-trained Google News Word2Vec embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2b6bc6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selected search term: Student\n",
      "Top 10 job titles by Word2Vec similarity to search term:\n",
      "Student (Score: 1.000)\n",
      "Student at Chapman University (Score: 0.807)\n",
      "Student at Chapman University (Score: 0.807)\n",
      "Student at Chapman University (Score: 0.807)\n",
      "Student at Chapman University (Score: 0.807)\n",
      "Student at Westfield State University (Score: 0.793)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (Score: 0.575)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (Score: 0.575)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (Score: 0.575)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (Score: 0.575)\n"
     ]
    }
   ],
   "source": [
    "# Download Google News vectors (only needs to be done once)\n",
    "# w2v = api.load('word2vec-google-news-300')\n",
    "w2v = api.load(\"word2vec-google-news-300\")\n",
    "\n",
    "\n",
    "def get_w2v_vector(text, model):\n",
    "    words = [w for w in nltk.word_tokenize(text.lower()) if w in model]\n",
    "    if not words:\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean([model[w] for w in words], axis=0)\n",
    "\n",
    "\n",
    "# Load the Excel file containing potential talents data\n",
    "# (Assumes the file is in the same directory as the notebook)\n",
    "df = pd.read_excel(\"potential-talents.xlsx\")\n",
    "\n",
    "# List of possible column names that may contain job titles\n",
    "possible_columns = [\n",
    "    \"job_title\",\n",
    "    \"title\",\n",
    "    \"position\",\n",
    "    \"role\",\n",
    "    \"job\",\n",
    "    \"designation\",\n",
    "    \"job title\",\n",
    "]\n",
    "\n",
    "# Initialize variable to store the detected job title column name\n",
    "job_title_column = None\n",
    "# Loop through columns in the DataFrame to find a matching job title column\n",
    "for col in df.columns:\n",
    "    if any(keyword in col.lower() for keyword in possible_columns):\n",
    "        job_title_column = col  # Set the column name if a match is found\n",
    "        break\n",
    "# Raise an error if no job title column is found\n",
    "default_job_title_error = \"Job title column not found. Please specify it manually.\"\n",
    "if not job_title_column:\n",
    "    raise ValueError(default_job_title_error)\n",
    "\n",
    "# Extract job titles as a list of strings, dropping missing values\n",
    "job_titles = df[job_title_column].dropna().astype(str).tolist()\n",
    "\n",
    "# Filter job titles to only those with 1 or 2 words\n",
    "filtered_job_titles = [title for title in job_titles if 1 <= len(title.split()) <= 2]\n",
    "\n",
    "# Randomly select a search term from filtered job titles\n",
    "if filtered_job_titles:\n",
    "    search_term = random.choice(filtered_job_titles)\n",
    "else:\n",
    "    raise ValueError(\"No job titles with 1 or 2 words found.\")\n",
    "\n",
    "# Print the randomly selected search term\n",
    "print(f\"Randomly selected search term: {search_term}\")\n",
    "\n",
    "job_vecs = np.array([get_w2v_vector(title, w2v) for title in job_titles])\n",
    "search_vec = get_w2v_vector(search_term, w2v).reshape(1, -1)\n",
    "similarities = cosine_similarity(search_vec, job_vecs).flatten()\n",
    "ranked_indices = np.argsort(similarities)[::-1]\n",
    "print(\"Top 10 job titles by Word2Vec similarity to search term:\")\n",
    "for idx in ranked_indices[:10]:\n",
    "    print(f\"{job_titles[idx]} (Score: {similarities[idx]:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10e7eef",
   "metadata": {},
   "source": [
    "## 5. GloVe Vectorization & Cosine Similarity\n",
    "Vectorize using pre-trained GloVe embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b2d2bbca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 job titles by GloVe similarity to search term:\n",
      "Student (Score: 1.000)\n",
      "Student at Chapman University (Score: 0.766)\n",
      "Student at Chapman University (Score: 0.766)\n",
      "Student at Chapman University (Score: 0.766)\n",
      "Student at Chapman University (Score: 0.766)\n",
      "Student at Westfield State University (Score: 0.699)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (Score: 0.669)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (Score: 0.669)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (Score: 0.669)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (Score: 0.669)\n"
     ]
    }
   ],
   "source": [
    "# Download GloVe vectors (only needs to be done once)\n",
    "# glove = api.load('glove-wiki-gigaword-300')\n",
    "glove = api.load(\"glove-wiki-gigaword-300\")\n",
    "\n",
    "\n",
    "def get_glove_vector(text, model):\n",
    "    words = [w for w in nltk.word_tokenize(text.lower()) if w in model]\n",
    "    if not words:\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean([model[w] for w in words], axis=0)\n",
    "\n",
    "\n",
    "job_vecs = np.array([get_glove_vector(title, glove) for title in job_titles])\n",
    "search_vec = get_glove_vector(search_term, glove).reshape(1, -1)\n",
    "similarities = cosine_similarity(search_vec, job_vecs).flatten()\n",
    "ranked_indices = np.argsort(similarities)[::-1]\n",
    "print(\"Top 10 job titles by GloVe similarity to search term:\")\n",
    "for idx in ranked_indices[:10]:\n",
    "    print(f\"{job_titles[idx]} (Score: {similarities[idx]:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c981e80",
   "metadata": {},
   "source": [
    "## 6. FastText Vectorization & Cosine Similarity\n",
    "Vectorize using pre-trained FastText embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fd5538c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 job titles by FastText similarity to search term:\n",
      "Student (Score: 1.000)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (Score: 0.724)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (Score: 0.724)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (Score: 0.724)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (Score: 0.724)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (Score: 0.724)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (Score: 0.724)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (Score: 0.724)\n",
      "Student at Chapman University (Score: 0.709)\n",
      "Student at Chapman University (Score: 0.709)\n"
     ]
    }
   ],
   "source": [
    "# Download FastText vectors (only needs to be done once)\n",
    "# fasttext_model = api.load('fasttext-wiki-news-subwords-300')\n",
    "fasttext_model = api.load(\"fasttext-wiki-news-subwords-300\")\n",
    "\n",
    "\n",
    "def get_fasttext_vector(text, model):\n",
    "    words = [w for w in nltk.word_tokenize(text.lower()) if w in model]\n",
    "    if not words:\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean([model[w] for w in words], axis=0)\n",
    "\n",
    "\n",
    "job_vecs = np.array(\n",
    "    [get_fasttext_vector(title, fasttext_model) for title in job_titles]\n",
    ")\n",
    "search_vec = get_fasttext_vector(search_term, fasttext_model).reshape(1, -1)\n",
    "similarities = cosine_similarity(search_vec, job_vecs).flatten()\n",
    "ranked_indices = np.argsort(similarities)[::-1]\n",
    "print(\"Top 10 job titles by FastText similarity to search term:\")\n",
    "for idx in ranked_indices[:10]:\n",
    "    print(f\"{job_titles[idx]} (Score: {similarities[idx]:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f51b2e2",
   "metadata": {},
   "source": [
    "## 7. BLEU Score Calculation\n",
    "Calculate BLEU score for semantic similarity between search term and job titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d238ce7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 job titles by BLEU semantic similarity to search term:\n",
      "Student (BLEU Score: 1.000)\n",
      "Student at Chapman University (BLEU Score: 0.061)\n",
      "Student at Chapman University (BLEU Score: 0.061)\n",
      "Student at Chapman University (BLEU Score: 0.061)\n",
      "Student at Chapman University (BLEU Score: 0.061)\n",
      "Student at Westfield State University (BLEU Score: 0.046)\n",
      "Aspiring Human Resources Management student seeking an internship (BLEU Score: 0.029)\n",
      "Aspiring Human Resources Management student seeking an internship (BLEU Score: 0.029)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (BLEU Score: 0.026)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (BLEU Score: 0.026)\n"
     ]
    }
   ],
   "source": [
    "# Calculate BLEU score for each job title against the search term\n",
    "smoothie = SmoothingFunction().method4\n",
    "search_tokens = nltk.word_tokenize(search_term.lower())\n",
    "bleu_scores = [\n",
    "    sentence_bleu(\n",
    "        [search_tokens], nltk.word_tokenize(title.lower()), smoothing_function=smoothie\n",
    "    )\n",
    "    for title in job_titles\n",
    "]\n",
    "ranked_indices = np.argsort(bleu_scores)[::-1]\n",
    "print(\"Top 10 job titles by BLEU semantic similarity to search term:\")\n",
    "for idx in ranked_indices[:10]:\n",
    "    print(f\"{job_titles[idx]} (BLEU Score: {bleu_scores[idx]:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2f4e3d",
   "metadata": {},
   "source": [
    "## 8. METEOR Score Calculation\n",
    "Calculate METEOR score for semantic similarity. METEOR considers synonyms and stemming, making it more suitable for semantic similarity than BLEU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9b8c5f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 job titles by METEOR semantic similarity to search term:\n",
      "Student (METEOR Score: 0.500)\n",
      "Student at Chapman University (METEOR Score: 0.385)\n",
      "Student at Chapman University (METEOR Score: 0.385)\n",
      "Student at Chapman University (METEOR Score: 0.385)\n",
      "Student at Chapman University (METEOR Score: 0.385)\n",
      "Student at Westfield State University (METEOR Score: 0.357)\n",
      "Aspiring Human Resources Management student seeking an internship (METEOR Score: 0.294)\n",
      "Aspiring Human Resources Management student seeking an internship (METEOR Score: 0.294)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (METEOR Score: 0.278)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (METEOR Score: 0.278)\n"
     ]
    }
   ],
   "source": [
    "# Import METEOR function from utils\n",
    "from utils import meteor\n",
    "\n",
    "# Calculate METEOR score for each job title against the search term\n",
    "search_tokens = nltk.word_tokenize(search_term.lower())\n",
    "meteor_scores = [\n",
    "    meteor_score([search_tokens], nltk.word_tokenize(title.lower()))\n",
    "    for title in job_titles\n",
    "]\n",
    "meteor_rank = np.argsort(meteor_scores)[::-1]\n",
    "\n",
    "print(\"Top 10 job titles by METEOR semantic similarity to search term:\")\n",
    "for idx in meteor_rank[:10]:\n",
    "    print(f\"{job_titles[idx]} (METEOR Score: {meteor_scores[idx]:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4f5a8b",
   "metadata": {},
   "source": [
    "## 9. CIDEr Score Calculation\n",
    "Calculate CIDEr (Consensus-based Image Description Evaluation) score. Originally for image captioning, but useful for semantic similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7d3e1a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 job titles by CIDEr semantic similarity to search term:\n",
      "Student (CIDEr Score: 1.000)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (CIDEr Score: 0.125)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (CIDEr Score: 0.125)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (CIDEr Score: 0.125)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (CIDEr Score: 0.125)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (CIDEr Score: 0.125)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (CIDEr Score: 0.125)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (CIDEr Score: 0.125)\n",
      "Student at Chapman University (CIDEr Score: 0.105)\n",
      "Student at Chapman University (CIDEr Score: 0.105)\n"
     ]
    }
   ],
   "source": [
    "# Import optimized CiderScorer from utils\n",
    "from utils import CiderScorer\n",
    "\n",
    "# Instantiate one CiderScorer with job_titles once to avoid O(N²) IDF recomputation\n",
    "cider = CiderScorer(job_titles)\n",
    "cider_scores = [cider.score(search_term, t) for t in job_titles]\n",
    "cider_rank = np.argsort(cider_scores)[::-1]\n",
    "\n",
    "print(\"Top 10 job titles by CIDEr semantic similarity to search term:\")\n",
    "for idx in cider_rank[:10]:\n",
    "    print(f\"{job_titles[idx]} (CIDEr Score: {cider_scores[idx]:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8e9c7a",
   "metadata": {},
   "source": [
    "## 10. Comprehensive Metric Comparison\n",
    "Compare all methods and recommend the best approach for job title semantic similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5e7f2b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COMPREHENSIVE COMPARISON OF SEMANTIC SIMILARITY METRICS ===\n",
      "\n",
      "Top match from each method:\n",
      "\n",
      "TF-IDF + Cosine:\n",
      "  Job Title: Student\n",
      "  Score: 1.000\n",
      "\n",
      "Word2Vec + Cosine:\n",
      "  Job Title: Student\n",
      "  Score: 1.000\n",
      "\n",
      "GloVe + Cosine:\n",
      "  Job Title: Student\n",
      "  Score: 1.000\n",
      "\n",
      "FastText + Cosine:\n",
      "  Job Title: Student\n",
      "  Score: 1.000\n",
      "\n",
      "BLEU Score:\n",
      "  Job Title: Student\n",
      "  Score: 1.000\n",
      "\n",
      "METEOR Score:\n",
      "  Job Title: Student\n",
      "  Score: 0.500\n",
      "\n",
      "CIDEr Score:\n",
      "  Job Title: Student\n",
      "  Score: 1.000\n",
      "\n",
      "=== RECOMMENDATION ===\n",
      "\n",
      "For job title semantic similarity, here's the ranking of methods:\n",
      "\n",
      "1. **GloVe + Cosine Similarity** (BEST CHOICE)\n",
      "   - Excellent semantic understanding\n",
      "   - Good balance of performance and accuracy\n",
      "   - Handles out-of-vocabulary words reasonably\n",
      "2. **Word2Vec + Cosine Similarity** (Second Choice)\n",
      "   - Strong semantic relationships\n",
      "   - Trained on Google News, good for professional terms\n",
      "3. **FastText + Cosine Similarity** (Third Choice)\n",
      "   - Handles subword information well\n",
      "   - Good for rare or misspelled words\n",
      "4. **METEOR Score** (Best for text generation evaluation)\n",
      "   - Considers synonyms and stemming\n",
      "   - Better than BLEU for semantic similarity\n",
      "5. **CIDEr Score** (Good for consensus-based evaluation)\n",
      "   - Uses TF-IDF weighting\n",
      "   - Good when you have multiple reference texts\n",
      "6. **TF-IDF + Cosine Similarity** (Baseline)\n",
      "   - Simple and fast\n",
      "   - Limited semantic understanding\n",
      "7. **BLEU Score** (Not recommended for this task)\n",
      "   - Designed for machine translation\n",
      "   - Poor for semantic similarity of short texts\n",
      "\n",
      "**FINAL RECOMMENDATION: Use GloVe + Cosine Similarity**\n",
      "This method provides the best balance of semantic understanding,\n",
      "computational efficiency, and practical performance for job title matching.\n"
     ]
    }
   ],
   "source": [
    "# Create a comprehensive comparison\n",
    "print(\"=== COMPREHENSIVE COMPARISON OF SEMANTIC SIMILARITY METRICS ===\\n\")\n",
    "\n",
    "# Get top result from each method\n",
    "methods = {\n",
    "    \"TF-IDF + Cosine\": (np.argsort(similarities)[::-1], similarities),\n",
    "    \"Word2Vec + Cosine\": (np.argsort(similarities)[::-1], similarities),\n",
    "    \"GloVe + Cosine\": (np.argsort(similarities)[::-1], similarities),\n",
    "    \"FastText + Cosine\": (np.argsort(similarities)[::-1], similarities),\n",
    "    \"BLEU Score\": (np.argsort(bleu_scores)[::-1], bleu_scores),\n",
    "    \"METEOR Score\": (np.argsort(meteor_scores)[::-1], meteor_scores),\n",
    "    \"CIDEr Score\": (np.argsort(cider_scores)[::-1], cider_scores),\n",
    "}\n",
    "\n",
    "print(\"Top match from each method:\")\n",
    "for method_name, (ranked_idx, scores) in methods.items():\n",
    "    top_idx = ranked_idx[0]\n",
    "    print(f\"\\n{method_name}:\")\n",
    "    print(f\"  Job Title: {job_titles[top_idx]}\")\n",
    "    print(f\"  Score: {scores[top_idx]:.3f}\")\n",
    "\n",
    "print(\"\\n=== RECOMMENDATION ===\")\n",
    "print(\"\\nFor job title semantic similarity, here's the ranking of methods:\")\n",
    "print(\"\\n1. **GloVe + Cosine Similarity** (BEST CHOICE)\")\n",
    "print(\"   - Excellent semantic understanding\")\n",
    "print(\"   - Good balance of performance and accuracy\")\n",
    "print(\"   - Handles out-of-vocabulary words reasonably\")\n",
    "\n",
    "print(\"2. **Word2Vec + Cosine Similarity** (Second Choice)\")\n",
    "print(\"   - Strong semantic relationships\")\n",
    "print(\"   - Trained on Google News, good for professional terms\")\n",
    "\n",
    "print(\"3. **FastText + Cosine Similarity** (Third Choice)\")\n",
    "print(\"   - Handles subword information well\")\n",
    "print(\"   - Good for rare or misspelled words\")\n",
    "\n",
    "print(\"4. **METEOR Score** (Best for text generation evaluation)\")\n",
    "print(\"   - Considers synonyms and stemming\")\n",
    "print(\"   - Better than BLEU for semantic similarity\")\n",
    "\n",
    "print(\"5. **CIDEr Score** (Good for consensus-based evaluation)\")\n",
    "print(\"   - Uses TF-IDF weighting\")\n",
    "print(\"   - Good when you have multiple reference texts\")\n",
    "\n",
    "print(\"6. **TF-IDF + Cosine Similarity** (Baseline)\")\n",
    "print(\"   - Simple and fast\")\n",
    "print(\"   - Limited semantic understanding\")\n",
    "\n",
    "print(\"7. **BLEU Score** (Not recommended for this task)\")\n",
    "print(\"   - Designed for machine translation\")\n",
    "print(\"   - Poor for semantic similarity of short texts\")\n",
    "\n",
    "print(\"\\n**FINAL RECOMMENDATION: Use GloVe + Cosine Similarity**\")\n",
    "print(\"This method provides the best balance of semantic understanding,\")\n",
    "print(\"computational efficiency, and practical performance for job title matching.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c1ba59fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM-ranked job titles:\n",
      " Here is the ranked list of job titles by how well they match the search term 'Student':\n",
      "\n",
      "1. Student\n",
      "2. Student at Westfield State University\n",
      "3. Student at Indiana University Kokomo - Business Management - \n",
      "4. Student at Humber College and Aspiring Human Resources Generalist\n",
      "5. Student at Chapman University\n",
      "6. Business Management Major and Aspiring Human Resources Manager\n",
      "7. Liberal Arts Major. Aspiring Human Resources Analyst.\n",
      "8. Human Resources Management Major\n",
      "9. Undergraduate Research Assistant at Styczynski Lab\n",
      "10. 2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "\n",
      "The rest of the job titles do not match the search term 'Student' as well, as they are more focused on human resources, management, or other fields.\n"
     ]
    }
   ],
   "source": [
    "# --- Simple LLM-based Candidate Ranking using Groq API (Llama 3 70B Versatile) ---\n",
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "def simple_llm_rank(job_titles, search_term):\n",
    "    api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise ValueError(\n",
    "            \"GROQ_API_KEY not found in environment variables. Please set it in your .env file.\"\n",
    "        )\n",
    "    prompt = (\n",
    "        f\"Rank these job titles by how well they match the search term '{search_term}'. Return a numbered list, most relevant first.\\n\"\n",
    "        + \"\\n\".join(job_titles)\n",
    "    )\n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n",
    "    data = {\n",
    "        \"model\": \"llama3-70b-8192\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"temperature\": 0.2,\n",
    "    }\n",
    "    response = requests.post(\n",
    "        \"https://api.groq.com/openai/v1/chat/completions\", headers=headers, json=data\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    result = response.json()\n",
    "    llm_output = result[\"choices\"][0][\"message\"][\"content\"]\n",
    "    print(\"LLM-ranked job titles:\\n\", llm_output)\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "simple_llm_rank(job_titles, search_term)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
