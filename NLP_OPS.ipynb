{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8268e07",
   "metadata": {},
   "source": [
    "# NLP Operations: Job Title Matching\n",
    "This notebook demonstrates various NLP techniques to vectorize job titles and a search term, and then ranks candidates by similarity. Techniques covered:\n",
    "- TF-IDF\n",
    "- Word2Vec (Google)\n",
    "- GloVe\n",
    "- FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52638f5",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports\n",
    "Install and import required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "840e55cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Osama\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Osama\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Osama\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Install required packages (uncomment if running for the first time)\n",
    "# !pip install pandas scikit-learn gensim nltk\n",
    "# !pip install glove-python-binary\n",
    "# !pip install fasttext\n",
    "# !pip install nltk pycocoevalcap\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import gensim.downloader as api\n",
    "from gensim.models import KeyedVectors\n",
    "import fasttext\n",
    "import fasttext.util\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "import random\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Import custom utility functions\n",
    "from utils import bleu_score\n",
    "\n",
    "# For CIDEr, we'll implement a simplified version\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"omw-1.4\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d735f83d",
   "metadata": {},
   "source": [
    "## 2. Load Data\n",
    "Load job titles from the Excel file and define a search term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb0b36a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selected search term: Student\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(\"potential-talents.xlsx\")\n",
    "possible_columns = [\n",
    "    \"job_title\",\n",
    "    \"title\",\n",
    "    \"position\",\n",
    "    \"role\",\n",
    "    \"job\",\n",
    "    \"designation\",\n",
    "    \"job title\",\n",
    "]\n",
    "job_title_column = None\n",
    "for col in df.columns:\n",
    "    if any(keyword in col.lower() for keyword in possible_columns):\n",
    "        job_title_column = col\n",
    "        break\n",
    "if not job_title_column:\n",
    "    raise ValueError(\"Job title column not found. Please specify it manually.\")\n",
    "job_titles = df[job_title_column].dropna().astype(str).tolist()\n",
    "\n",
    "# Filter job titles to only those with 1 or 2 words\n",
    "filtered_job_titles = [title for title in job_titles if 1 <= len(title.split()) <= 2]\n",
    "\n",
    "# Randomly select a search term from filtered job titles\n",
    "if filtered_job_titles:\n",
    "    search_term = random.choice(filtered_job_titles)\n",
    "else:\n",
    "    raise ValueError(\"No job titles with 1 or 2 words found.\")\n",
    "\n",
    "print(f\"Randomly selected search term: {search_term}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee2b628",
   "metadata": {},
   "source": [
    "## 3. TF-IDF Vectorization & Cosine Similarity\n",
    "Vectorize job titles and search term using TF-IDF, then rank candidates by similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78bd229b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 job titles by TF-IDF similarity to search term:\n",
      "Student (Score: 1.000)\n",
      "Student at Chapman University (Score: 0.455)\n",
      "Student at Chapman University (Score: 0.455)\n",
      "Student at Chapman University (Score: 0.455)\n",
      "Student at Chapman University (Score: 0.455)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (Score: 0.371)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (Score: 0.371)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (Score: 0.371)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (Score: 0.371)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (Score: 0.371)\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer()\n",
    "corpus = job_titles + [search_term]\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "search_vec = X[-1]\n",
    "job_vecs = X[:-1]\n",
    "similarities = cosine_similarity(search_vec, job_vecs).flatten()\n",
    "ranked_indices = np.argsort(similarities)[::-1]\n",
    "print(\"Top 10 job titles by TF-IDF similarity to search term:\")\n",
    "for idx in ranked_indices[:10]:\n",
    "    print(f\"{job_titles[idx]} (Score: {similarities[idx]:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9af1a7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- LLM-based Candidate Ranking using Groq API (Llama 3 70B Versatile) ---\n",
    "# import requests\n",
    "# import os\n",
    "# import json\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "# # Load environment variables from .env file\n",
    "# load_dotenv()\n",
    "\n",
    "\n",
    "# def rank_candidates_with_llm(\n",
    "#     job_titles, search_term, model=\"llama3-70b-8192\"\n",
    "# ):  # Llama 3 70B Versatile\n",
    "#     \"\"\"\n",
    "#     Use Groq LLM API to rank job titles by relevance to the search term.\n",
    "#     Args:\n",
    "#         job_titles (list): List of job title strings.\n",
    "#         search_term (str): The search term/job title to match against.\n",
    "#         model (str): Groq model name (default: llama3-70b-8192).\n",
    "#     Returns:\n",
    "#         list: Ranked job titles (most relevant first).\n",
    "#     \"\"\"\n",
    "#     api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "#     if not api_key:\n",
    "#         raise ValueError(\n",
    "#             \"GROQ_API_KEY not found in environment variables. Please set it in your .env file.\"\n",
    "#         )\n",
    "#     prompt = f\"\"\"\n",
    "# You are an expert recruiter. Given the following list of candidate job titles, rank them from most to least relevant for the search term: '{search_term}'.\\n\\nJob Titles:\\n\"\"\"\n",
    "#     for i, title in enumerate(job_titles, 1):\n",
    "#         prompt += f\"{i}. {title}\\n\"\n",
    "#     prompt += \"\\nReturn the ranking as a numbered list, most relevant first. Only include the job titles.\"\n",
    "\n",
    "#     headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n",
    "#     data = {\n",
    "#         \"model\": model,\n",
    "#         \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "#         \"temperature\": 0.2,\n",
    "#     }\n",
    "#     response = requests.post(\n",
    "#         \"https://api.groq.com/openai/v1/chat/completions\",\n",
    "#         headers=headers,\n",
    "#         data=json.dumps(data),\n",
    "#     )\n",
    "#     response.raise_for_status()\n",
    "#     result = response.json()\n",
    "#     llm_output = result[\"choices\"][0][\"message\"][\"content\"]\n",
    "#     # Parse the LLM output into a ranked list\n",
    "#     ranked = [\n",
    "#         line.split(\". \", 1)[-1].strip()\n",
    "#         for line in llm_output.split(\"\\n\")\n",
    "#         if line.strip() and line[0].isdigit()\n",
    "#     ]\n",
    "#     return ranked\n",
    "\n",
    "\n",
    "# # Example usage:\n",
    "# # ranked_list = rank_candidates_with_llm(job_titles, search_term)\n",
    "# # print(\"LLM-ranked job titles:\")\n",
    "# # for title in ranked_list:\n",
    "# #     print(title)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff0288f",
   "metadata": {},
   "source": [
    "## 4. Word2Vec (Google News) Vectorization & Cosine Similarity\n",
    "Vectorize using pre-trained Google News Word2Vec embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b6bc6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selected search term: Student\n",
      "Top 10 job titles by Word2Vec similarity to search term:\n",
      "Student (Score: 1.000)\n",
      "Student at Chapman University (Score: 0.807)\n",
      "Student at Chapman University (Score: 0.807)\n",
      "Student at Chapman University (Score: 0.807)\n",
      "Student at Chapman University (Score: 0.807)\n",
      "Student at Westfield State University (Score: 0.793)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (Score: 0.575)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (Score: 0.575)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (Score: 0.575)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (Score: 0.575)\n",
      "Top 10 job titles by Word2Vec similarity to search term:\n",
      "Student (Score: 1.000)\n",
      "Student at Chapman University (Score: 0.807)\n",
      "Student at Chapman University (Score: 0.807)\n",
      "Student at Chapman University (Score: 0.807)\n",
      "Student at Chapman University (Score: 0.807)\n",
      "Student at Westfield State University (Score: 0.793)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (Score: 0.575)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (Score: 0.575)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (Score: 0.575)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (Score: 0.575)\n"
     ]
    }
   ],
   "source": [
    "# Download Google News vectors (only needs to be done once)\n",
    "# w2v = api.load('word2vec-google-news-300')\n",
    "w2v = api.load(\"word2vec-google-news-300\")\n",
    "\n",
    "\n",
    "def get_w2v_vector(text, model):\n",
    "    words = [w for w in nltk.word_tokenize(text.lower()) if w in model]\n",
    "    if not words:\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean([model[w] for w in words], axis=0)\n",
    "\n",
    "\n",
    "# Load the Excel file containing potential talents data\n",
    "# (Assumes the file is in the same directory as the notebook)\n",
    "df = pd.read_excel(\"potential-talents.xlsx\")\n",
    "\n",
    "# List of possible column names that may contain job titles\n",
    "possible_columns = [\n",
    "    \"job_title\",\n",
    "    \"title\",\n",
    "    \"position\",\n",
    "    \"role\",\n",
    "    \"job\",\n",
    "    \"designation\",\n",
    "    \"job title\",\n",
    "]\n",
    "\n",
    "# Initialize variable to store the detected job title column name\n",
    "job_title_column = None\n",
    "# Loop through columns in the DataFrame to find a matching job title column\n",
    "for col in df.columns:\n",
    "    if any(keyword in col.lower() for keyword in possible_columns):\n",
    "        job_title_column = col  # Set the column name if a match is found\n",
    "        break\n",
    "# Raise an error if no job title column is found\n",
    "default_job_title_error = \"Job title column not found. Please specify it manually.\"\n",
    "if not job_title_column:\n",
    "    raise ValueError(default_job_title_error)\n",
    "\n",
    "# Extract job titles as a list of strings, dropping missing values\n",
    "job_titles = df[job_title_column].dropna().astype(str).tolist()\n",
    "\n",
    "# Filter job titles to only those with 1 or 2 words\n",
    "filtered_job_titles = [title for title in job_titles if 1 <= len(title.split()) <= 2]\n",
    "\n",
    "# Randomly select a search term from filtered job titles\n",
    "if filtered_job_titles:\n",
    "    search_term = random.choice(filtered_job_titles)\n",
    "else:\n",
    "    raise ValueError(\"No job titles with 1 or 2 words found.\")\n",
    "\n",
    "# Print the randomly selected search term\n",
    "print(f\"Randomly selected search term: {search_term}\")\n",
    "\n",
    "job_vecs = np.array([get_w2v_vector(title, w2v) for title in job_titles])\n",
    "search_vec = get_w2v_vector(search_term, w2v).reshape(1, -1)\n",
    "similarities = cosine_similarity(search_vec, job_vecs).flatten()\n",
    "ranked_indices = np.argsort(similarities)[::-1]\n",
    "print(\"Top 10 job titles by Word2Vec similarity to search term:\")\n",
    "for idx in ranked_indices[:10]:\n",
    "    print(f\"{job_titles[idx]} (Score: {similarities[idx]:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10e7eef",
   "metadata": {},
   "source": [
    "## 5. GloVe Vectorization & Cosine Similarity\n",
    "Vectorize using pre-trained GloVe embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2d2bbca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 job titles by GloVe similarity to search term:\n",
      "Student (Score: 1.000)\n",
      "Student at Chapman University (Score: 0.766)\n",
      "Student at Chapman University (Score: 0.766)\n",
      "Student at Chapman University (Score: 0.766)\n",
      "Student at Chapman University (Score: 0.766)\n",
      "Student at Westfield State University (Score: 0.699)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (Score: 0.669)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (Score: 0.669)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (Score: 0.669)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (Score: 0.669)\n"
     ]
    }
   ],
   "source": [
    "# Download GloVe vectors (only needs to be done once)\n",
    "# glove = api.load('glove-wiki-gigaword-300')\n",
    "glove = api.load(\"glove-wiki-gigaword-300\")\n",
    "\n",
    "\n",
    "def get_glove_vector(text, model):\n",
    "    words = [w for w in nltk.word_tokenize(text.lower()) if w in model]\n",
    "    if not words:\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean([model[w] for w in words], axis=0)\n",
    "\n",
    "\n",
    "job_vecs = np.array([get_glove_vector(title, glove) for title in job_titles])\n",
    "search_vec = get_glove_vector(search_term, glove).reshape(1, -1)\n",
    "similarities = cosine_similarity(search_vec, job_vecs).flatten()\n",
    "ranked_indices = np.argsort(similarities)[::-1]\n",
    "print(\"Top 10 job titles by GloVe similarity to search term:\")\n",
    "for idx in ranked_indices[:10]:\n",
    "    print(f\"{job_titles[idx]} (Score: {similarities[idx]:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c981e80",
   "metadata": {},
   "source": [
    "## 6. FastText Vectorization & Cosine Similarity\n",
    "Vectorize using pre-trained FastText embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd5538c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Download FastText vectors (only needs to be done once)\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# fasttext_model = api.load('fasttext-wiki-news-subwords-300')\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m fasttext_model = \u001b[43mapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfasttext-wiki-news-subwords-300\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_fasttext_vector\u001b[39m(text, model):\n\u001b[32m      7\u001b[39m     words = [w \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m nltk.word_tokenize(text.lower()) \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m model]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Repositories\\Apziva Projects\\Project 3\\Potential-Talents\\env\\Lib\\site-packages\\gensim\\downloader.py:503\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(name, return_path)\u001b[39m\n\u001b[32m    501\u001b[39m sys.path.insert(\u001b[32m0\u001b[39m, BASE_DIR)\n\u001b[32m    502\u001b[39m module = \u001b[38;5;28m__import__\u001b[39m(name)\n\u001b[32m--> \u001b[39m\u001b[32m503\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gensim-data\\fasttext-wiki-news-subwords-300\\__init__.py:8\u001b[39m, in \u001b[36mload_data\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_data\u001b[39m():\n\u001b[32m      7\u001b[39m     path = os.path.join(base_dir, \u001b[33m'\u001b[39m\u001b[33mfasttext-wiki-news-subwords-300\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfasttext-wiki-news-subwords-300.gz\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     model = \u001b[43mKeyedVectors\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_word2vec_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Repositories\\Apziva Projects\\Project 3\\Potential-Talents\\env\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:1719\u001b[39m, in \u001b[36mKeyedVectors.load_word2vec_format\u001b[39m\u001b[34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001b[39m\n\u001b[32m   1672\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m   1673\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_word2vec_format\u001b[39m(\n\u001b[32m   1674\u001b[39m         \u001b[38;5;28mcls\u001b[39m, fname, fvocab=\u001b[38;5;28;01mNone\u001b[39;00m, binary=\u001b[38;5;28;01mFalse\u001b[39;00m, encoding=\u001b[33m'\u001b[39m\u001b[33mutf8\u001b[39m\u001b[33m'\u001b[39m, unicode_errors=\u001b[33m'\u001b[39m\u001b[33mstrict\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   1675\u001b[39m         limit=\u001b[38;5;28;01mNone\u001b[39;00m, datatype=REAL, no_header=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   1676\u001b[39m     ):\n\u001b[32m   1677\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load KeyedVectors from a file produced by the original C word2vec-tool format.\u001b[39;00m\n\u001b[32m   1678\u001b[39m \n\u001b[32m   1679\u001b[39m \u001b[33;03m    Warnings\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1717\u001b[39m \n\u001b[32m   1718\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_word2vec_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1720\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfvocab\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbinary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43municode_errors\u001b[49m\u001b[43m=\u001b[49m\u001b[43municode_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1721\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatatype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdatatype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mno_header\u001b[49m\u001b[43m=\u001b[49m\u001b[43mno_header\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1722\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Repositories\\Apziva Projects\\Project 3\\Potential-Talents\\env\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:2069\u001b[39m, in \u001b[36m_load_word2vec_format\u001b[39m\u001b[34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001b[39m\n\u001b[32m   2065\u001b[39m         _word2vec_read_binary(\n\u001b[32m   2066\u001b[39m             fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, binary_chunk_size, encoding\n\u001b[32m   2067\u001b[39m         )\n\u001b[32m   2068\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2069\u001b[39m         \u001b[43m_word2vec_read_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcounts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvector_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatatype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43municode_errors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kv.vectors.shape[\u001b[32m0\u001b[39m] != \u001b[38;5;28mlen\u001b[39m(kv):\n\u001b[32m   2071\u001b[39m     logger.info(\n\u001b[32m   2072\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mduplicate words detected, shrinking matrix size from \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[33m to \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   2073\u001b[39m         kv.vectors.shape[\u001b[32m0\u001b[39m], \u001b[38;5;28mlen\u001b[39m(kv),\n\u001b[32m   2074\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Repositories\\Apziva Projects\\Project 3\\Potential-Talents\\env\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:1971\u001b[39m, in \u001b[36m_word2vec_read_text\u001b[39m\u001b[34m(fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, encoding)\u001b[39m\n\u001b[32m   1969\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_word2vec_read_text\u001b[39m(fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, encoding):\n\u001b[32m   1970\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m line_no \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(vocab_size):\n\u001b[32m-> \u001b[39m\u001b[32m1971\u001b[39m         line = \u001b[43mfin\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1972\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m line == \u001b[33mb\u001b[39m\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m   1973\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33munexpected end of input; is count incorrect or file otherwise damaged?\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\gzip.py:427\u001b[39m, in \u001b[36mGzipFile.readline\u001b[39m\u001b[34m(self, size)\u001b[39m\n\u001b[32m    425\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreadline\u001b[39m(\u001b[38;5;28mself\u001b[39m, size=-\u001b[32m1\u001b[39m):\n\u001b[32m    426\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_not_closed()\n\u001b[32m--> \u001b[39m\u001b[32m427\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_buffer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\_compression.py:68\u001b[39m, in \u001b[36mDecompressReader.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreadinto\u001b[39m(\u001b[38;5;28mself\u001b[39m, b):\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(b) \u001b[38;5;28;01mas\u001b[39;00m view, view.cast(\u001b[33m\"\u001b[39m\u001b[33mB\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m byte_view:\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbyte_view\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m         byte_view[:\u001b[38;5;28mlen\u001b[39m(data)] = data\n\u001b[32m     70\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\gzip.py:550\u001b[39m, in \u001b[36m_GzipReader.read\u001b[39m\u001b[34m(self, size)\u001b[39m\n\u001b[32m    546\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buf == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    547\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCompressed file ended before the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    548\u001b[39m                        \u001b[33m\"\u001b[39m\u001b[33mend-of-stream marker was reached\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m550\u001b[39m \u001b[38;5;28mself\u001b[39m._crc = \u001b[43mzlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcrc32\u001b[49m\u001b[43m(\u001b[49m\u001b[43muncompress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_crc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[38;5;28mself\u001b[39m._stream_size += \u001b[38;5;28mlen\u001b[39m(uncompress)\n\u001b[32m    552\u001b[39m \u001b[38;5;28mself\u001b[39m._pos += \u001b[38;5;28mlen\u001b[39m(uncompress)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Download FastText vectors (only needs to be done once)\n",
    "# fasttext_model = api.load('fasttext-wiki-news-subwords-300')\n",
    "fasttext_model = api.load(\"fasttext-wiki-news-subwords-300\")\n",
    "\n",
    "\n",
    "def get_fasttext_vector(text, model):\n",
    "    words = [w for w in nltk.word_tokenize(text.lower()) if w in model]\n",
    "    if not words:\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean([model[w] for w in words], axis=0)\n",
    "\n",
    "\n",
    "job_vecs = np.array(\n",
    "    [get_fasttext_vector(title, fasttext_model) for title in job_titles]\n",
    ")\n",
    "search_vec = get_fasttext_vector(search_term, fasttext_model).reshape(1, -1)\n",
    "similarities = cosine_similarity(search_vec, job_vecs).flatten()\n",
    "ranked_indices = np.argsort(similarities)[::-1]\n",
    "print(\"Top 10 job titles by FastText similarity to search term:\")\n",
    "for idx in ranked_indices[:10]:\n",
    "    print(f\"{job_titles[idx]} (Score: {similarities[idx]:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f51b2e2",
   "metadata": {},
   "source": [
    "## 7. BLEU Score Calculation\n",
    "Calculate BLEU score for semantic similarity between search term and job titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d238ce7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 job titles by BLEU semantic similarity to search term:\n",
      "Student (BLEU Score: 1.000)\n",
      "Student at Chapman University (BLEU Score: 0.061)\n",
      "Student at Chapman University (BLEU Score: 0.061)\n",
      "Student at Chapman University (BLEU Score: 0.061)\n",
      "Student at Chapman University (BLEU Score: 0.061)\n",
      "Student at Westfield State University (BLEU Score: 0.046)\n",
      "Aspiring Human Resources Management student seeking an internship (BLEU Score: 0.029)\n",
      "Aspiring Human Resources Management student seeking an internship (BLEU Score: 0.029)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (BLEU Score: 0.026)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (BLEU Score: 0.026)\n"
     ]
    }
   ],
   "source": [
    "# Calculate BLEU score for each job title against the search term\n",
    "smoothie = SmoothingFunction().method4\n",
    "search_tokens = nltk.word_tokenize(search_term.lower())\n",
    "bleu_scores = [\n",
    "    sentence_bleu(\n",
    "        [search_tokens], nltk.word_tokenize(title.lower()), smoothing_function=smoothie\n",
    "    )\n",
    "    for title in job_titles\n",
    "]\n",
    "ranked_indices = np.argsort(bleu_scores)[::-1]\n",
    "print(\"Top 10 job titles by BLEU semantic similarity to search term:\")\n",
    "for idx in ranked_indices[:10]:\n",
    "    print(f\"{job_titles[idx]} (BLEU Score: {bleu_scores[idx]:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2f4e3d",
   "metadata": {},
   "source": [
    "## 8. METEOR Score Calculation\n",
    "Calculate METEOR score for semantic similarity. METEOR considers synonyms and stemming, making it more suitable for semantic similarity than BLEU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8c5f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 job titles by METEOR semantic similarity to search term:\n",
      "Student (METEOR Score: 0.500)\n",
      "Student at Chapman University (METEOR Score: 0.385)\n",
      "Student at Chapman University (METEOR Score: 0.385)\n",
      "Student at Chapman University (METEOR Score: 0.385)\n",
      "Student at Chapman University (METEOR Score: 0.385)\n",
      "Student at Westfield State University (METEOR Score: 0.357)\n",
      "Aspiring Human Resources Management student seeking an internship (METEOR Score: 0.294)\n",
      "Aspiring Human Resources Management student seeking an internship (METEOR Score: 0.294)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (METEOR Score: 0.278)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (METEOR Score: 0.278)\n"
     ]
    }
   ],
   "source": [
    "# Import METEOR function from utils\n",
    "from utils import meteor\n",
    "\n",
    "# Calculate METEOR score for each job title against the search term\n",
    "search_tokens = nltk.word_tokenize(search_term.lower())\n",
    "meteor_scores = [\n",
    "    meteor_score([search_tokens], nltk.word_tokenize(title.lower()))\n",
    "    for title in job_titles\n",
    "]\n",
    "meteor_rank = np.argsort(meteor_scores)[::-1]\n",
    "\n",
    "print(\"Top 10 job titles by METEOR semantic similarity to search term:\")\n",
    "for idx in meteor_rank[:10]:\n",
    "    print(f\"{job_titles[idx]} (METEOR Score: {meteor_scores[idx]:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4f5a8b",
   "metadata": {},
   "source": [
    "## 9. CIDEr Score Calculation\n",
    "Calculate CIDEr (Consensus-based Image Description Evaluation) score. Originally for image captioning, but useful for semantic similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3e1a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 job titles by CIDEr semantic similarity to search term:\n",
      "Student (CIDEr Score: 1.000)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (CIDEr Score: 0.125)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (CIDEr Score: 0.125)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (CIDEr Score: 0.125)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (CIDEr Score: 0.125)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (CIDEr Score: 0.125)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (CIDEr Score: 0.125)\n",
      "Student at Humber College and Aspiring Human Resources Generalist (CIDEr Score: 0.125)\n",
      "Student at Chapman University (CIDEr Score: 0.105)\n",
      "Student at Chapman University (CIDEr Score: 0.105)\n"
     ]
    }
   ],
   "source": [
    "# Import optimized CiderScorer from utils\n",
    "from utils import CiderScorer\n",
    "\n",
    "# Instantiate one CiderScorer with job_titles once to avoid O(NÂ²) IDF recomputation\n",
    "cider = CiderScorer(job_titles)\n",
    "cider_scores = [cider.score(search_term, t) for t in job_titles]\n",
    "cider_rank = np.argsort(cider_scores)[::-1]\n",
    "\n",
    "print(\"Top 10 job titles by CIDEr semantic similarity to search term:\")\n",
    "for idx in cider_rank[:10]:\n",
    "    print(f\"{job_titles[idx]} (CIDEr Score: {cider_scores[idx]:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8e9c7a",
   "metadata": {},
   "source": [
    "## 10. Comprehensive Metric Comparison\n",
    "Compare all methods and recommend the best approach for job title semantic similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7f2b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COMPREHENSIVE COMPARISON OF SEMANTIC SIMILARITY METRICS ===\n",
      "\n",
      "Top match from each method:\n",
      "\n",
      "TF-IDF + Cosine:\n",
      "  Job Title: Student\n",
      "  Score: 1.000\n",
      "\n",
      "Word2Vec + Cosine:\n",
      "  Job Title: Student\n",
      "  Score: 1.000\n",
      "\n",
      "GloVe + Cosine:\n",
      "  Job Title: Student\n",
      "  Score: 1.000\n",
      "\n",
      "FastText + Cosine:\n",
      "  Job Title: Student\n",
      "  Score: 1.000\n",
      "\n",
      "BLEU Score:\n",
      "  Job Title: Student\n",
      "  Score: 1.000\n",
      "\n",
      "METEOR Score:\n",
      "  Job Title: Student\n",
      "  Score: 0.500\n",
      "\n",
      "CIDEr Score:\n",
      "  Job Title: Student\n",
      "  Score: 1.000\n",
      "\n",
      "=== RECOMMENDATION ===\n",
      "\n",
      "For job title semantic similarity, here's the ranking of methods:\n",
      "\n",
      "1. **GloVe + Cosine Similarity** (BEST CHOICE)\n",
      "   - Excellent semantic understanding\n",
      "   - Good balance of performance and accuracy\n",
      "   - Handles out-of-vocabulary words reasonably\n",
      "2. **Word2Vec + Cosine Similarity** (Second Choice)\n",
      "   - Strong semantic relationships\n",
      "   - Trained on Google News, good for professional terms\n",
      "3. **FastText + Cosine Similarity** (Third Choice)\n",
      "   - Handles subword information well\n",
      "   - Good for rare or misspelled words\n",
      "4. **METEOR Score** (Best for text generation evaluation)\n",
      "   - Considers synonyms and stemming\n",
      "   - Better than BLEU for semantic similarity\n",
      "5. **CIDEr Score** (Good for consensus-based evaluation)\n",
      "   - Uses TF-IDF weighting\n",
      "   - Good when you have multiple reference texts\n",
      "6. **TF-IDF + Cosine Similarity** (Baseline)\n",
      "   - Simple and fast\n",
      "   - Limited semantic understanding\n",
      "7. **BLEU Score** (Not recommended for this task)\n",
      "   - Designed for machine translation\n",
      "   - Poor for semantic similarity of short texts\n",
      "\n",
      "**FINAL RECOMMENDATION: Use GloVe + Cosine Similarity**\n",
      "This method provides the best balance of semantic understanding,\n",
      "computational efficiency, and practical performance for job title matching.\n"
     ]
    }
   ],
   "source": [
    "# Create a comprehensive comparison\n",
    "print(\"=== COMPREHENSIVE COMPARISON OF SEMANTIC SIMILARITY METRICS ===\\n\")\n",
    "\n",
    "# Get top result from each method\n",
    "methods = {\n",
    "    \"TF-IDF + Cosine\": (np.argsort(similarities)[::-1], similarities),\n",
    "    \"Word2Vec + Cosine\": (np.argsort(similarities)[::-1], similarities),\n",
    "    \"GloVe + Cosine\": (np.argsort(similarities)[::-1], similarities),\n",
    "    \"FastText + Cosine\": (np.argsort(similarities)[::-1], similarities),\n",
    "    \"BLEU Score\": (np.argsort(bleu_scores)[::-1], bleu_scores),\n",
    "    \"METEOR Score\": (np.argsort(meteor_scores)[::-1], meteor_scores),\n",
    "    \"CIDEr Score\": (np.argsort(cider_scores)[::-1], cider_scores),\n",
    "}\n",
    "\n",
    "print(\"Top match from each method:\")\n",
    "for method_name, (ranked_idx, scores) in methods.items():\n",
    "    top_idx = ranked_idx[0]\n",
    "    print(f\"\\n{method_name}:\")\n",
    "    print(f\"  Job Title: {job_titles[top_idx]}\")\n",
    "    print(f\"  Score: {scores[top_idx]:.3f}\")\n",
    "\n",
    "print(\"\\n=== RECOMMENDATION ===\")\n",
    "print(\"\\nFor job title semantic similarity, here's the ranking of methods:\")\n",
    "print(\"\\n1. **GloVe + Cosine Similarity** (BEST CHOICE)\")\n",
    "print(\"   - Excellent semantic understanding\")\n",
    "print(\"   - Good balance of performance and accuracy\")\n",
    "print(\"   - Handles out-of-vocabulary words reasonably\")\n",
    "\n",
    "print(\"2. **Word2Vec + Cosine Similarity** (Second Choice)\")\n",
    "print(\"   - Strong semantic relationships\")\n",
    "print(\"   - Trained on Google News, good for professional terms\")\n",
    "\n",
    "print(\"3. **FastText + Cosine Similarity** (Third Choice)\")\n",
    "print(\"   - Handles subword information well\")\n",
    "print(\"   - Good for rare or misspelled words\")\n",
    "\n",
    "print(\"4. **METEOR Score** (Best for text generation evaluation)\")\n",
    "print(\"   - Considers synonyms and stemming\")\n",
    "print(\"   - Better than BLEU for semantic similarity\")\n",
    "\n",
    "print(\"5. **CIDEr Score** (Good for consensus-based evaluation)\")\n",
    "print(\"   - Uses TF-IDF weighting\")\n",
    "print(\"   - Good when you have multiple reference texts\")\n",
    "\n",
    "print(\"6. **TF-IDF + Cosine Similarity** (Baseline)\")\n",
    "print(\"   - Simple and fast\")\n",
    "print(\"   - Limited semantic understanding\")\n",
    "\n",
    "print(\"7. **BLEU Score** (Not recommended for this task)\")\n",
    "print(\"   - Designed for machine translation\")\n",
    "print(\"   - Poor for semantic similarity of short texts\")\n",
    "\n",
    "print(\"\\n**FINAL RECOMMENDATION: Use GloVe + Cosine Similarity**\")\n",
    "print(\"This method provides the best balance of semantic understanding,\")\n",
    "print(\"computational efficiency, and practical performance for job title matching.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ba59fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM-ranked job titles:\n",
      " Here is the list of job titles ranked by how well they match the search term 'Student', with the most relevant first:\n",
      "\n",
      "1. Student\n",
      "2. Student at Westfield State University\n",
      "3. Student at Indiana University Kokomo - Business Management - \n",
      "4. Student at Humber College and Aspiring Human Resources Generalist\n",
      "5. Student at Humber College and Aspiring Human Resources Generalist\n",
      "6. Student at Chapman University\n",
      "7. Aspiring Human Resources Management student seeking an internship\n",
      "8. Aspiring Human Resources Management student seeking an internship\n",
      "9. Liberal Arts Major. Aspiring Human Resources Analyst.\n",
      "10. Business Management Major and Aspiring Human Resources Manager.\n",
      "\n",
      "The remaining job titles do not contain the word \"Student\" and are therefore less relevant to the search term.\n"
     ]
    }
   ],
   "source": [
    "# --- Simple LLM-based Candidate Ranking using Groq API (Llama 3 70B Versatile) ---\n",
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "def simple_llm_rank(job_titles, search_term):\n",
    "    api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise ValueError(\n",
    "            \"GROQ_API_KEY not found in environment variables. Please set it in your .env file.\"\n",
    "        )\n",
    "    prompt = (\n",
    "        f\"Rank these job titles by how well they match the search term '{search_term}'. Return a numbered list, most relevant first.\\n\"\n",
    "        + \"\\n\".join(job_titles)\n",
    "    )\n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n",
    "    data = {\n",
    "        \"model\": \"llama3-70b-8192\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"temperature\": 0.2,\n",
    "    }\n",
    "    response = requests.post(\n",
    "        \"https://api.groq.com/openai/v1/chat/completions\", headers=headers, json=data\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    result = response.json()\n",
    "    llm_output = result[\"choices\"][0][\"message\"][\"content\"]\n",
    "    print(\"LLM-ranked job titles:\\n\", llm_output)\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "simple_llm_rank(job_titles, search_term)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2528dba1",
   "metadata": {},
   "source": [
    "## 11. Transformer-based Contextual Embeddings (BERT/Sentence-BERT)\n",
    "Use Sentence-BERT to generate contextual embeddings for job titles and the search term, then rank by cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87f3aa5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 job titles by SBERT similarity to search term:\n",
      "Student (Score: 1.000)\n",
      "Student at Westfield State University (Score: 0.616)\n",
      "Student at Chapman University (Score: 0.602)\n",
      "Student at Chapman University (Score: 0.602)\n",
      "Student at Chapman University (Score: 0.602)\n",
      "Student at Chapman University (Score: 0.602)\n",
      "Student at Indiana University Kokomo - Business Management - \n",
      "Retail Manager at Delphi Hardware and Paint (Score: 0.409)\n",
      "Advisory Board Member at Celal Bayar University (Score: 0.398)\n",
      "Advisory Board Member at Celal Bayar University (Score: 0.398)\n",
      "Advisory Board Member at Celal Bayar University (Score: 0.398)\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Load a pre-trained Sentence-BERT model\n",
    "sbert_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Compute embeddings\n",
    "job_embeddings = sbert_model.encode(job_titles)\n",
    "search_embedding = sbert_model.encode([search_term])\n",
    "\n",
    "# Compute cosine similarities\n",
    "similarities = cosine_similarity(search_embedding, job_embeddings).flatten()\n",
    "ranked_indices = np.argsort(similarities)[::-1]\n",
    "\n",
    "print(\"Top 10 job titles by SBERT similarity to search term:\")\n",
    "for idx in ranked_indices[:10]:\n",
    "    print(f\"{job_titles[idx]} (Score: {similarities[idx]:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8316614",
   "metadata": {},
   "source": [
    "## 12. Compare Multiple Transformer Models (Gemma, Qwen, etc.)\n",
    "Experiment with different Hugging Face transformer models for ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72816f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ranking with model: sentence-transformers/all-MiniLM-L6-v2\n",
      "Student (Score: 0.609)\n",
      "Student at Westfield State University (Score: 0.472)\n",
      "Student at Indiana University Kokomo - Business Management - \n",
      "Retail Manager at Delphi Hardware and Paint (Score: 0.447)\n",
      "Student at Chapman University (Score: 0.441)\n",
      "Student at Chapman University (Score: 0.441)\n",
      "Student at Chapman University (Score: 0.441)\n",
      "Student at Chapman University (Score: 0.441)\n",
      "Advisory Board Member at Celal Bayar University (Score: 0.348)\n",
      "Advisory Board Member at Celal Bayar University (Score: 0.348)\n",
      "Advisory Board Member at Celal Bayar University (Score: 0.348)\n",
      "\n",
      "Ranking with model: Qwen/Qwen1.5-0.5B-Chat\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "781a0472d1a840778f89e72c2fb8d1d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Repositories\\Apziva Projects\\Project 3\\Potential-Talents\\env\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Osama\\.cache\\huggingface\\hub\\models--Qwen--Qwen1.5-0.5B-Chat. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a528746e2e3844ce8a7aae1cfa084b89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a63c0e0364d74f7890ee9490b9c566c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85cca257a01f4be8abf46d7015e0ce57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6845279351194e8a8908edb931123076",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/661 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84fe6bc2b4a846fcabbf1f52cc3d2d1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.24G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human Resources Professional (Score: 0.954)\n",
      "Human Resources Management Major (Score: 0.920)\n",
      "Human Resources Coordinator at InterContinental Buckhead Atlanta (Score: 0.619)\n",
      "Human Resources Coordinator at InterContinental Buckhead Atlanta (Score: 0.619)\n",
      "Human Resources Coordinator at InterContinental Buckhead Atlanta (Score: 0.619)\n",
      "Human Resources Coordinator at InterContinental Buckhead Atlanta (Score: 0.619)\n",
      "Seeking Human Resources Opportunities (Score: 0.510)\n",
      "Seeking Human Resources Opportunities (Score: 0.510)\n",
      "Seeking Human Resources Position (Score: 0.457)\n",
      "Human Resources Specialist at Luxottica (Score: 0.228)\n",
      "\n",
      "Ranking with model: google/gemma-2b-it\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/google/gemma-2b-it.\n401 Client Error. (Request ID: Root=1-68532383-109c14b203ce714f4793ca33;75adf809-962c-458e-b688-bde86812f18e)\n\nCannot access gated repo for url https://huggingface.co/google/gemma-2b-it/resolve/main/config.json.\nAccess to model google/gemma-2b-it is restricted. You must have access to it and be authenticated to access it. Please log in.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Repositories\\Apziva Projects\\Project 3\\Potential-Talents\\env\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:409\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m409\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Repositories\\Apziva Projects\\Project 3\\Potential-Talents\\env\\Lib\\site-packages\\requests\\models.py:1026\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 401 Client Error: Unauthorized for url: https://huggingface.co/google/gemma-2b-it/resolve/main/config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mGatedRepoError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Repositories\\Apziva Projects\\Project 3\\Potential-Talents\\env\\Lib\\site-packages\\transformers\\utils\\hub.py:470\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    468\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) == \u001b[32m1\u001b[39m:\n\u001b[32m    469\u001b[39m     \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m470\u001b[39m     \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    471\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    472\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    473\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Repositories\\Apziva Projects\\Project 3\\Potential-Talents\\env\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Repositories\\Apziva Projects\\Project 3\\Potential-Talents\\env\\Lib\\site-packages\\huggingface_hub\\file_download.py:1008\u001b[39m, in \u001b[36mhf_hub_download\u001b[39m\u001b[34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[39m\n\u001b[32m   1007\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1008\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[32m   1012\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[32m   1017\u001b[39m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1018\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1019\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1020\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1021\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1022\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[32m   1023\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Repositories\\Apziva Projects\\Project 3\\Potential-Talents\\env\\Lib\\site-packages\\huggingface_hub\\file_download.py:1115\u001b[39m, in \u001b[36m_hf_hub_download_to_cache_dir\u001b[39m\u001b[34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[39m\n\u001b[32m   1114\u001b[39m     \u001b[38;5;66;03m# Otherwise, raise appropriate error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1115\u001b[39m     \u001b[43m_raise_on_head_call_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_call_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1117\u001b[39m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Repositories\\Apziva Projects\\Project 3\\Potential-Talents\\env\\Lib\\site-packages\\huggingface_hub\\file_download.py:1645\u001b[39m, in \u001b[36m_raise_on_head_call_error\u001b[39m\u001b[34m(head_call_error, force_download, local_files_only)\u001b[39m\n\u001b[32m   1640\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, (RepositoryNotFoundError, GatedRepoError)) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1641\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(head_call_error, HfHubHTTPError) \u001b[38;5;129;01mand\u001b[39;00m head_call_error.response.status_code == \u001b[32m401\u001b[39m\n\u001b[32m   1642\u001b[39m ):\n\u001b[32m   1643\u001b[39m     \u001b[38;5;66;03m# Repo not found or gated => let's raise the actual error\u001b[39;00m\n\u001b[32m   1644\u001b[39m     \u001b[38;5;66;03m# Unauthorized => likely a token issue => let's raise the actual error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1645\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m head_call_error\n\u001b[32m   1646\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1647\u001b[39m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Repositories\\Apziva Projects\\Project 3\\Potential-Talents\\env\\Lib\\site-packages\\huggingface_hub\\file_download.py:1533\u001b[39m, in \u001b[36m_get_metadata_or_catch_error\u001b[39m\u001b[34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[39m\n\u001b[32m   1532\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1533\u001b[39m     metadata = \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1534\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\n\u001b[32m   1535\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1536\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Repositories\\Apziva Projects\\Project 3\\Potential-Talents\\env\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Repositories\\Apziva Projects\\Project 3\\Potential-Talents\\env\\Lib\\site-packages\\huggingface_hub\\file_download.py:1450\u001b[39m, in \u001b[36mget_hf_file_metadata\u001b[39m\u001b[34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[39m\n\u001b[32m   1449\u001b[39m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1450\u001b[39m r = \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1451\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHEAD\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1452\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1453\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1454\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1455\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1456\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1457\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1458\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1459\u001b[39m hf_raise_for_status(r)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Repositories\\Apziva Projects\\Project 3\\Potential-Talents\\env\\Lib\\site-packages\\huggingface_hub\\file_download.py:286\u001b[39m, in \u001b[36m_request_wrapper\u001b[39m\u001b[34m(method, url, follow_relative_redirects, **params)\u001b[39m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     response = \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    293\u001b[39m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[32m    294\u001b[39m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Repositories\\Apziva Projects\\Project 3\\Potential-Talents\\env\\Lib\\site-packages\\huggingface_hub\\file_download.py:310\u001b[39m, in \u001b[36m_request_wrapper\u001b[39m\u001b[34m(method, url, follow_relative_redirects, **params)\u001b[39m\n\u001b[32m    309\u001b[39m response = http_backoff(method=method, url=url, **params, retry_on_exceptions=(), retry_on_status_codes=(\u001b[32m429\u001b[39m,))\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Repositories\\Apziva Projects\\Project 3\\Potential-Talents\\env\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:426\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    423\u001b[39m     message = (\n\u001b[32m    424\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Client Error.\u001b[39m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot access gated repo for url \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    425\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m426\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m _format(GatedRepoError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    428\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m error_message == \u001b[33m\"\u001b[39m\u001b[33mAccess to this resource is disabled.\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[31mGatedRepoError\u001b[39m: 401 Client Error. (Request ID: Root=1-68532383-109c14b203ce714f4793ca33;75adf809-962c-458e-b688-bde86812f18e)\n\nCannot access gated repo for url https://huggingface.co/google/gemma-2b-it/resolve/main/config.json.\nAccess to model google/gemma-2b-it is restricted. You must have access to it and be authenticated to access it. Please log in.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m model_names:\n\u001b[32m     22\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mRanking with model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     job_embs = \u001b[43mget_transformer_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_titles\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m     search_emb = get_transformer_embeddings(model_name, [search_term])\n\u001b[32m     25\u001b[39m     sims = cosine_similarity(search_emb, job_embs).flatten()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mget_transformer_embeddings\u001b[39m\u001b[34m(model_name, texts)\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_transformer_embeddings\u001b[39m(model_name, texts):\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     tokenizer = \u001b[43mAutoTokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     model = AutoModel.from_pretrained(model_name)\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Repositories\\Apziva Projects\\Project 3\\Potential-Talents\\env\\Lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:970\u001b[39m, in \u001b[36mAutoTokenizer.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[39m\n\u001b[32m    968\u001b[39m         config = AutoConfig.for_model(**config_dict)\n\u001b[32m    969\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m970\u001b[39m         config = \u001b[43mAutoConfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    973\u001b[39m config_tokenizer_class = config.tokenizer_class\n\u001b[32m    974\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(config, \u001b[33m\"\u001b[39m\u001b[33mauto_map\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mAutoTokenizer\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config.auto_map:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Repositories\\Apziva Projects\\Project 3\\Potential-Talents\\env\\Lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py:1153\u001b[39m, in \u001b[36mAutoConfig.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[39m\n\u001b[32m   1150\u001b[39m trust_remote_code = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mtrust_remote_code\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m   1151\u001b[39m code_revision = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mcode_revision\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1153\u001b[39m config_dict, unused_kwargs = \u001b[43mPretrainedConfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1154\u001b[39m has_remote_code = \u001b[33m\"\u001b[39m\u001b[33mauto_map\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mAutoConfig\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict[\u001b[33m\"\u001b[39m\u001b[33mauto_map\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1155\u001b[39m has_local_code = \u001b[33m\"\u001b[39m\u001b[33mmodel_type\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[33m\"\u001b[39m\u001b[33mmodel_type\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m CONFIG_MAPPING\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Repositories\\Apziva Projects\\Project 3\\Potential-Talents\\env\\Lib\\site-packages\\transformers\\configuration_utils.py:595\u001b[39m, in \u001b[36mPretrainedConfig.get_config_dict\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[39m\n\u001b[32m    593\u001b[39m original_kwargs = copy.deepcopy(kwargs)\n\u001b[32m    594\u001b[39m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m595\u001b[39m config_dict, kwargs = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    596\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    597\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {}, kwargs\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Repositories\\Apziva Projects\\Project 3\\Potential-Talents\\env\\Lib\\site-packages\\transformers\\configuration_utils.py:654\u001b[39m, in \u001b[36mPretrainedConfig._get_config_dict\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[39m\n\u001b[32m    650\u001b[39m configuration_file = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33m_configuration_file\u001b[39m\u001b[33m\"\u001b[39m, CONFIG_NAME) \u001b[38;5;28;01mif\u001b[39;00m gguf_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m gguf_file\n\u001b[32m    652\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    653\u001b[39m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m654\u001b[39m     resolved_config_file = \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfiguration_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    659\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    660\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    661\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    662\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    663\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    664\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    665\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    666\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    667\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    668\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    669\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, kwargs\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Repositories\\Apziva Projects\\Project 3\\Potential-Talents\\env\\Lib\\site-packages\\transformers\\utils\\hub.py:312\u001b[39m, in \u001b[36mcached_file\u001b[39m\u001b[34m(path_or_repo_id, filename, **kwargs)\u001b[39m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcached_file\u001b[39m(\n\u001b[32m    255\u001b[39m     path_or_repo_id: Union[\u001b[38;5;28mstr\u001b[39m, os.PathLike],\n\u001b[32m    256\u001b[39m     filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    257\u001b[39m     **kwargs,\n\u001b[32m    258\u001b[39m ) -> Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    259\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[33;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001b[39;00m\n\u001b[32m    261\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    310\u001b[39m \u001b[33;03m    ```\u001b[39;00m\n\u001b[32m    311\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m312\u001b[39m     file = \u001b[43mcached_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    313\u001b[39m     file = file[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[32m    314\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Repositories\\Apziva Projects\\Project 3\\Potential-Talents\\env\\Lib\\site-packages\\transformers\\utils\\hub.py:533\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    531\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _raise_exceptions_for_gated_repo:\n\u001b[32m    532\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m533\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[32m    534\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou are trying to access a gated repo.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mMake sure to have access to it at \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    535\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    536\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, LocalEntryNotFoundError):\n\u001b[32m    538\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _raise_exceptions_for_connection_errors:\n",
      "\u001b[31mOSError\u001b[39m: You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/google/gemma-2b-it.\n401 Client Error. (Request ID: Root=1-68532383-109c14b203ce714f4793ca33;75adf809-962c-458e-b688-bde86812f18e)\n\nCannot access gated repo for url https://huggingface.co/google/gemma-2b-it/resolve/main/config.json.\nAccess to model google/gemma-2b-it is restricted. You must have access to it and be authenticated to access it. Please log in."
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "\n",
    "def get_transformer_embeddings(model_name, texts):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name)\n",
    "    with torch.no_grad():\n",
    "        encoded = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        output = model(**encoded)\n",
    "        embeddings = output.last_hidden_state.mean(dim=1).numpy()\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "model_names = [\n",
    "    \"sentence-transformers/all-MiniLM-L6-v2\",  # SBERT baseline\n",
    "    \"Qwen/Qwen1.5-0.5B-Chat\",  # Qwen (if available)\n",
    "    \"google/gemma-2b-it\",  # Gemma 2B (if available)\n",
    "]\n",
    "\n",
    "for model_name in model_names:\n",
    "    print(f\"\\nRanking with model: {model_name}\")\n",
    "    job_embs = get_transformer_embeddings(model_name, job_titles)\n",
    "    search_emb = get_transformer_embeddings(model_name, [search_term])\n",
    "    sims = cosine_similarity(search_emb, job_embs).flatten()\n",
    "    top_idx = np.argsort(sims)[::-1]\n",
    "    for idx in top_idx[:10]:\n",
    "        print(f\"{job_titles[idx]} (Score: {sims[idx]:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c389654b",
   "metadata": {},
   "source": [
    "## 13. LLM-based Ranking with Multiple Models (Llama 3, Gemma, Qwen)\n",
    "Use Groq API to rank job titles with different LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8906deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "def llm_rank(job_titles, search_term, model_name):\n",
    "    api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "    prompt = (\n",
    "        f\"Rank these job titles by how well they match the search term '{search_term}'. \"\n",
    "        \"Return a numbered list, most relevant first.\\n\\n\" + \"\\n\".join(job_titles)\n",
    "    )\n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n",
    "    data = {\n",
    "        \"model\": model_name,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"temperature\": 0.2,\n",
    "    }\n",
    "    response = requests.post(\n",
    "        \"https://api.groq.com/openai/v1/chat/completions\",\n",
    "        headers=headers,\n",
    "        data=json.dumps(data),\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    result = response.json()\n",
    "    llm_output = result[\"choices\"][0][\"message\"][\"content\"]\n",
    "    ranked = [\n",
    "        line.split(\". \", 1)[-1].strip()\n",
    "        for line in llm_output.split(\"\\n\")\n",
    "        if line.strip() and line[0].isdigit()\n",
    "    ]\n",
    "    return ranked\n",
    "\n",
    "\n",
    "for model in [\"llama3-70b-8192\", \"google/gemma-2b-it\", \"Qwen/Qwen1.5-0.5B-Chat\"]:\n",
    "    print(f\"\\nLLM Ranking with {model}:\")\n",
    "    ranked = llm_rank(job_titles, search_term, model)\n",
    "    for i, title in enumerate(ranked[:10], 1):\n",
    "        print(f\"{i}. {title}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
