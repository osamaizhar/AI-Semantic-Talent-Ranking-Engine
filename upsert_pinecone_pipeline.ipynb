{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All imports and inits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from transformers import AutoTokenizer\n",
    "from pinecone import Pinecone\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "DATA_PATH = os.getenv(\"DATA_PATH\")\n",
    "PINECONE_API = os.getenv(\"PINECONE_API\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excel Parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded ./potential-talents.xlsx\n",
      "Processed 104 rows from Excel file\n",
      "\n",
      "Example document:\n",
      "{'content': 'id: 1 job_title: 2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional location: Houston, Texas connection: 85 fit: nan', 'metadata': {'source': './potential-talents.xlsx', 'file_type': 'excel', 'row_id': 0}}\n"
     ]
    }
   ],
   "source": [
    "def load_excel_document():\n",
    "    \"\"\"\n",
    "    Load data from potential_clients.xlsx file\n",
    "    Returns a list of documents with content and metadata\n",
    "    \"\"\"\n",
    "\n",
    "    documents = []\n",
    "\n",
    "    try:\n",
    "        # Read the Excel file\n",
    "        df = pd.read_excel(DATA_PATH)\n",
    "        print(f\"Successfully loaded {DATA_PATH}\")\n",
    "\n",
    "        # Convert each row to a document\n",
    "        for idx, row in df.iterrows():\n",
    "            # Convert row to string representation\n",
    "            content = \" \".join([f\"{col}: {str(row[col])}\" for col in df.columns])\n",
    "\n",
    "            # Create document with content and metadata\n",
    "            documents.append(\n",
    "                {\n",
    "                    \"content\": content,\n",
    "                    \"metadata\": {\n",
    "                        \"source\": DATA_PATH,\n",
    "                        \"file_type\": \"excel\",\n",
    "                        \"row_id\": idx,\n",
    "                    },\n",
    "                }\n",
    "            )\n",
    "\n",
    "        print(f\"Processed {len(documents)} rows from Excel file\")\n",
    "        return documents\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading Excel file: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "# Load documents from Excel\n",
    "documents = load_excel_document()\n",
    "\n",
    "# Display first document as example\n",
    "if documents:\n",
    "    print(\"\\nExample document:\")\n",
    "    print(documents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Splitting \\ Chunking for llama text embed v2 via pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'id: 1 job_title: 2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional location: Houston, Texas connection: 85 fit: nan', 'metadata': {'source': './potential-talents.xlsx', 'file_type': 'excel', 'row_id': 0, 'chunk_id': 0}}\n",
      "Tokens:  40\n"
     ]
    }
   ],
   "source": [
    "def count_tokens(text: str) -> int:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"jinaai/jina-embeddings-v2-base-en\")\n",
    "    # Encode the text into tokens\n",
    "    tokens = tokenizer.encode(text)\n",
    "    return len(tokens)\n",
    "\n",
    "\n",
    "def split_documents(documents):\n",
    "    # Each chunk is ~800-1000 tokens to leave room for metadata tokens if needed\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=32000,  # fit comfortably within 2048 token limit\n",
    "        chunk_overlap=16000,  # helps retain context between chunks\n",
    "        length_function=len,  # use token length if tokenizer available\n",
    "        is_separator_regex=True,  # respect newline and semantic breaks\n",
    "    )\n",
    "\n",
    "    chunks = []\n",
    "\n",
    "    for doc in documents:\n",
    "        split_texts = text_splitter.split_text(doc[\"content\"])\n",
    "\n",
    "        for i, chunk in enumerate(split_texts):\n",
    "            chunks.append(\n",
    "                {\"content\": chunk, \"metadata\": {**doc[\"metadata\"], \"chunk_id\": i}}\n",
    "            )\n",
    "    return chunks\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "chunks = split_documents(documents)\n",
    "\n",
    "# print(len(chunks))\n",
    "print(chunks[0])\n",
    "print(\n",
    "    \"Tokens: \", count_tokens(chunks[0][\"content\"])\n",
    ")  # Check if splitting looks reasonable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(api_key=PINECONE_API)\n",
    "# print(PINECONE_API)\n",
    "\n",
    "# Connect to the index\n",
    "index = pc.Index(\"potential-talents\")  # -- COMPLETE SURGICAL TECH BOOTCAMP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Emebddings and Upsertion functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Repositories\\Apziva Projects\\Project 3\\Potential-Talents\\env\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:407: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1 upserted to Pinecone with metadata\n",
      "Embedding 2 upserted to Pinecone with metadata\n",
      "Embedding 3 upserted to Pinecone with metadata\n",
      "Embedding 4 upserted to Pinecone with metadata\n",
      "Embedding 5 upserted to Pinecone with metadata\n",
      "Embedding 6 upserted to Pinecone with metadata\n",
      "Embedding 7 upserted to Pinecone with metadata\n",
      "Embedding 8 upserted to Pinecone with metadata\n",
      "Embedding 9 upserted to Pinecone with metadata\n",
      "Embedding 10 upserted to Pinecone with metadata\n",
      "Embedding 11 upserted to Pinecone with metadata\n",
      "Embedding 12 upserted to Pinecone with metadata\n",
      "Embedding 13 upserted to Pinecone with metadata\n",
      "Embedding 14 upserted to Pinecone with metadata\n",
      "Embedding 15 upserted to Pinecone with metadata\n",
      "Embedding 16 upserted to Pinecone with metadata\n",
      "Embedding 17 upserted to Pinecone with metadata\n",
      "Embedding 18 upserted to Pinecone with metadata\n",
      "Embedding 19 upserted to Pinecone with metadata\n",
      "Embedding 20 upserted to Pinecone with metadata\n",
      "Embedding 21 upserted to Pinecone with metadata\n",
      "Embedding 22 upserted to Pinecone with metadata\n",
      "Embedding 23 upserted to Pinecone with metadata\n",
      "Embedding 24 upserted to Pinecone with metadata\n",
      "Embedding 25 upserted to Pinecone with metadata\n",
      "Embedding 26 upserted to Pinecone with metadata\n",
      "Embedding 27 upserted to Pinecone with metadata\n",
      "Embedding 28 upserted to Pinecone with metadata\n",
      "Embedding 29 upserted to Pinecone with metadata\n",
      "Embedding 30 upserted to Pinecone with metadata\n",
      "Embedding 31 upserted to Pinecone with metadata\n",
      "Embedding 32 upserted to Pinecone with metadata\n",
      "Embedding 33 upserted to Pinecone with metadata\n",
      "Embedding 34 upserted to Pinecone with metadata\n",
      "Embedding 35 upserted to Pinecone with metadata\n",
      "Embedding 36 upserted to Pinecone with metadata\n",
      "Embedding 37 upserted to Pinecone with metadata\n",
      "Embedding 38 upserted to Pinecone with metadata\n",
      "Embedding 39 upserted to Pinecone with metadata\n",
      "Embedding 40 upserted to Pinecone with metadata\n",
      "Embedding 41 upserted to Pinecone with metadata\n",
      "Embedding 42 upserted to Pinecone with metadata\n",
      "Embedding 43 upserted to Pinecone with metadata\n",
      "Embedding 44 upserted to Pinecone with metadata\n",
      "Embedding 45 upserted to Pinecone with metadata\n",
      "Embedding 46 upserted to Pinecone with metadata\n",
      "Embedding 47 upserted to Pinecone with metadata\n",
      "Embedding 48 upserted to Pinecone with metadata\n",
      "Embedding 49 upserted to Pinecone with metadata\n",
      "Embedding 50 upserted to Pinecone with metadata\n",
      "Embedding 51 upserted to Pinecone with metadata\n",
      "Embedding 52 upserted to Pinecone with metadata\n",
      "Embedding 53 upserted to Pinecone with metadata\n",
      "Embedding 54 upserted to Pinecone with metadata\n",
      "Embedding 55 upserted to Pinecone with metadata\n",
      "Embedding 56 upserted to Pinecone with metadata\n",
      "Embedding 57 upserted to Pinecone with metadata\n",
      "Embedding 58 upserted to Pinecone with metadata\n",
      "Embedding 59 upserted to Pinecone with metadata\n",
      "Embedding 60 upserted to Pinecone with metadata\n",
      "Embedding 61 upserted to Pinecone with metadata\n",
      "Embedding 62 upserted to Pinecone with metadata\n",
      "Embedding 63 upserted to Pinecone with metadata\n",
      "Embedding 64 upserted to Pinecone with metadata\n",
      "Embedding 65 upserted to Pinecone with metadata\n",
      "Embedding 66 upserted to Pinecone with metadata\n",
      "Embedding 67 upserted to Pinecone with metadata\n",
      "Embedding 68 upserted to Pinecone with metadata\n",
      "Embedding 69 upserted to Pinecone with metadata\n",
      "Embedding 70 upserted to Pinecone with metadata\n",
      "Embedding 71 upserted to Pinecone with metadata\n",
      "Embedding 72 upserted to Pinecone with metadata\n",
      "Embedding 73 upserted to Pinecone with metadata\n",
      "Embedding 74 upserted to Pinecone with metadata\n",
      "Embedding 75 upserted to Pinecone with metadata\n",
      "Embedding 76 upserted to Pinecone with metadata\n",
      "Embedding 77 upserted to Pinecone with metadata\n",
      "Embedding 78 upserted to Pinecone with metadata\n",
      "Embedding 79 upserted to Pinecone with metadata\n",
      "Embedding 80 upserted to Pinecone with metadata\n",
      "Embedding 81 upserted to Pinecone with metadata\n",
      "Embedding 82 upserted to Pinecone with metadata\n",
      "Embedding 83 upserted to Pinecone with metadata\n",
      "Embedding 84 upserted to Pinecone with metadata\n",
      "Embedding 85 upserted to Pinecone with metadata\n",
      "Embedding 86 upserted to Pinecone with metadata\n",
      "Embedding 87 upserted to Pinecone with metadata\n",
      "Embedding 88 upserted to Pinecone with metadata\n",
      "Embedding 89 upserted to Pinecone with metadata\n",
      "Embedding 90 upserted to Pinecone with metadata\n",
      "Embedding 91 upserted to Pinecone with metadata\n",
      "Embedding 92 upserted to Pinecone with metadata\n",
      "Embedding 93 upserted to Pinecone with metadata\n",
      "Embedding 94 upserted to Pinecone with metadata\n",
      "Embedding 95 upserted to Pinecone with metadata\n",
      "Embedding 96 upserted to Pinecone with metadata\n",
      "Embedding 97 upserted to Pinecone with metadata\n",
      "Embedding 98 upserted to Pinecone with metadata\n",
      "Embedding 99 upserted to Pinecone with metadata\n",
      "Embedding 100 upserted to Pinecone with metadata\n",
      "Embedding 101 upserted to Pinecone with metadata\n",
      "Embedding 102 upserted to Pinecone with metadata\n",
      "Embedding 103 upserted to Pinecone with metadata\n",
      "Embedding 104 upserted to Pinecone with metadata\n",
      "All 104 embeddings have been upserted to Pinecone\n"
     ]
    }
   ],
   "source": [
    "sbert_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "def get_embedding(text=\"None\"):\n",
    "    # Generate embedding using the pre-loaded model\n",
    "    embedding = sbert_model.encode(text)\n",
    "\n",
    "    # Return the embedding as a list/array\n",
    "    return embedding.tolist()\n",
    "\n",
    "# print(len(get_embedding(\"Surgical Conscience\")))\n",
    "\n",
    "def upsert_chunks_to_pinecone(index, chunks):\n",
    "    count = 0\n",
    "    for chunk in chunks:\n",
    "        # Ensure the chunk has the correct structure\n",
    "        content = chunk.get(\"content\")\n",
    "        metadata = chunk.get(\"metadata\", {})\n",
    "\n",
    "        # Get the embedding for the chunk\n",
    "        # embedding = get_embedding(content).data[0]['values']\n",
    "        embedding = get_embedding(content)\n",
    "\n",
    "        # Add the text as part of the metadata\n",
    "        metadata[\"text\"] = content  # Store text in metadata\n",
    "        # metadata[\"token_count\"] = count_tokens(content)\n",
    "\n",
    "        # Create a unique vector ID for each chunk (e.g., based on count or some unique identifier)\n",
    "        vector_id = f\"vec_{count}\"\n",
    "\n",
    "        # Upsert the embedding along with its metadata\n",
    "        index.upsert(vectors=[(vector_id, embedding, metadata)])\n",
    "\n",
    "        count += 1\n",
    "        print(f\"Embedding {count} upserted to Pinecone with metadata\")\n",
    "\n",
    "    print(f\"All {count} embeddings have been upserted to Pinecone\")\n",
    "\n",
    "upsert_chunks_to_pinecone(index, chunks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
